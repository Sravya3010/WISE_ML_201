{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of IntroductiontoPandas1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sravya3010/WISE_ML_201/blob/main/Copy_of_IntroductiontoPandas1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMLXx6bXlaW_"
      },
      "source": [
        "# Objectives\n",
        "\n",
        "At the end of the experiment you will be able to \n",
        "\n",
        "* Understand importance of Pandas\n",
        "* Perform data cleaning, manipulation using Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjICDMPsbwpy"
      },
      "source": [
        "## Features of Pandas\n",
        "\n",
        "* Fast and efficient DataFrame object with default and customized indexing.\n",
        "* Tools for loading data into in-memory data objects from different file formats.\n",
        "* Data alignment and integrated handling of missing data.\n",
        "* Reshaping and pivoting of date sets.\n",
        "* Label-based slicing, indexing and subsetting of large data sets.\n",
        "* Columns from a data structure can be deleted or inserted.\n",
        "* Group by data for aggregation and transformations.\n",
        "* High performance merging and joining of data.\n",
        "* Time Series functionality.\n",
        "\n",
        "Now it is time to work on practicals. Following Are the given Exercise:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYXAtZ4al2AP"
      },
      "source": [
        "### Excercise 1: How to import pandas and check the version?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RDqknbwl7x_"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "pd.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv5M2Nx1bwp5"
      },
      "source": [
        "### Excercise 2: Create a Series from Dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdUZtU_fbwqC"
      },
      "source": [
        "dic_eg = {'name':['sravya','laasya','tanmayee']}\r\n",
        "pd.Series(dic_eg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UyGy_YbbwqT"
      },
      "source": [
        "### Exercise 3: Create a DataFrame from Lists ; coloumns heading should be 'Name', 'Age'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLB-s818bwqY"
      },
      "source": [
        "\r\n",
        "pd.DataFrame({'Name':['sravya','laasya','tanmayee'],'Age':[19,20,21]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gormGGPbwqj"
      },
      "source": [
        "### Exercise 4: Create a DataFrame from List of Dictionaries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS2xTZnlbwqm"
      },
      "source": [
        "listOfDictionaries = [{'name':'sravya','age':19,'gender':'F'},{'name':'venkatesh','age':19,'gender':'M'}]\r\n",
        "pd.DataFrame(listOfDictionaries)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UncsmSyLbws1"
      },
      "source": [
        "### Exercise 5: frame a dataset using following data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tvTQhXObws5"
      },
      "source": [
        "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\n",
        "'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\n",
        "'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
        "'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
        "'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4plT_YZ3mqCW"
      },
      "source": [
        "ipl_data = {'Team': ['Riders', 'Riders', 'Devils', 'Devils', 'Kings',\r\n",
        "'kings', 'Kings', 'Kings', 'Riders', 'Royals', 'Royals', 'Riders'],\r\n",
        "'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\r\n",
        "'Year': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\r\n",
        "'Points':[876,789,863,673,741,812,756,788,694,701,804,690]}\r\n",
        "df = pd.DataFrame(ipl_data)\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXnhjImzbwtC"
      },
      "source": [
        "### Exercise 6: In Ipl_data group the data by year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T5a2b4jbwtF"
      },
      "source": [
        "df.groupby('Year').groups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xQktTsHbwtX"
      },
      "source": [
        "### Exercise 7: In Ipl_data group the data by Team and year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFjaGQaKbwtY"
      },
      "source": [
        "df.groupby(['Year','Team']).groups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4q_6xsnbwth"
      },
      "source": [
        "### Exercise 8: Iterating through Groups using year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxoAYBhfbwtk"
      },
      "source": [
        "arranged = df.groupby('Year')\r\n",
        "for year,data in arranged:\r\n",
        "  print(year)\r\n",
        "  print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHwzd9Mwbwt0"
      },
      "source": [
        "### Exercise 9: Group the data and get only 2014 year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCbKf6tDbwt7"
      },
      "source": [
        "arranged = df.groupby('Year')\r\n",
        "print(arranged.get_group(2014))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqgXqS-AbwuC"
      },
      "source": [
        "### Exercise 10: In points do the mean using .agg i.e aggregate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO3DN2febwuM"
      },
      "source": [
        "grouped = df.groupby('Year')\r\n",
        "print(grouped['Points'].agg(np.mean))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59ZMHuNqbwua"
      },
      "source": [
        "### Exercise 11: Find size of dataset using **.agg** based on team"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPuFzKdJbwuj"
      },
      "source": [
        "grouped = df.groupby('Team')\r\n",
        "print(grouped.agg(np.size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U5NWns6bwvD"
      },
      "source": [
        "### Exercise 12: Create two Dataframes name it as 'left' and other 'right' using following data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0aGt0t9nEsI"
      },
      "source": [
        "left = pd.DataFrame({\r\n",
        "'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\r\n",
        "'subject_id':['sub1','sub2','sub4','sub6','sub5'],\r\n",
        "'Marks_scored':[98,90,87,69,78]},)\r\n",
        "right = pd.DataFrame({\r\n",
        "'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\r\n",
        "'subject_id':['sub2','sub4','sub3','sub6','sub5'],\r\n",
        "'Marks_scored':[89,80,79,97,88]},)\r\n",
        "print(left)\r\n",
        "print(right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43E3vj0CbwvZ"
      },
      "source": [
        "### Exercise 13: Merge the left and right based on 'id'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7hXk9usbwvc"
      },
      "source": [
        "left = pd.DataFrame({'id':[1,2,3,4,5],\r\n",
        "'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\r\n",
        "'subject_id':['sub1','sub2','sub4','sub6','sub5'],\r\n",
        "'Marks_scored':[98,90,87,69,78]},)\r\n",
        "right = pd.DataFrame({'id':[1,2,3,4,5],\r\n",
        "'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\r\n",
        "'subject_id':['sub2','sub4','sub3','sub6','sub5'],\r\n",
        "'Marks_scored':[89,80,79,97,88]},)\r\n",
        "print(pd.merge(left,right,on = 'id'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WxFdWACbwvf"
      },
      "source": [
        "### Exercise 14: Merge the left and right based on 'id' and 'subject_id'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHw6p0nwbwvh"
      },
      "source": [
        "print(pd.merge(left,right,on = ['id','subject_id']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or4g7TZ0bwvl"
      },
      "source": [
        "### Exercise 15: Merge the left and right based on 'subject_id' ,left join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tttLFvIHbwvm"
      },
      "source": [
        "print(pd.merge(left,right,on='subject_id',how = 'left'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Sc6Kobbwvq"
      },
      "source": [
        "### Exercise 16: Merge the left and right based on 'subject_id' ,right join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9qCcjepbwvs"
      },
      "source": [
        "print(pd.merge(left,right,on='subject_id',how = 'right'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp82DptPbwvv"
      },
      "source": [
        "### Exercise 17: Merge the left and right based on 'subject_id' ,outter join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ0U0rckbwvx"
      },
      "source": [
        "print(pd.merge(left,right,on='subject_id',how = 'outer'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR_XxuUcbwv1"
      },
      "source": [
        "### Exercise 18: Merge the left and right based on 'subject_id' ,inner join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmeJHglRbwv3"
      },
      "source": [
        "print(pd.merge(left,right,on='subject_id',how = 'inner'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXo3gMuubwv-"
      },
      "source": [
        "### Exercise 19: Concatinate two dataframes using following data and the index should not repeat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNcZ2uxkbwwC"
      },
      "source": [
        "first = pd.DataFrame({\n",
        "'Name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n",
        "'subject_id':['sub1','sub2','sub4','sub6','sub5'],\n",
        "'Marks_scored':[98,90,87,69,78]},\n",
        "index=[1,2,3,4,5])\n",
        "second = pd.DataFrame({\n",
        "'Name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n",
        "'subject_id':['sub2','sub4','sub3','sub6','sub5'],\n",
        "'Marks_scored':[89,80,79,97,88]},\n",
        "index=[1,2,3,4,5])\n",
        "pd.concat([first,second]).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DBxa4rDbwwJ"
      },
      "source": [
        "### Exercise 20: Change the header names of given data using .read_csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlEBO-M2bwwN"
      },
      "source": [
        "# Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}